{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\ana\\envs\\pytorch12\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from typing import Optional, Union, Tuple, Iterable\n","import freerec\n","from freerec.data.preprocessing import AtomicConverter"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# dataset\n","root: str = \"../RecSets/file_\"\n","filename: Optional[str] = \"ml-1m\"\n","# 'root/filename should' the directory storing '.inter' file\n","# 'dataset' below is the name of the dataset after processing\n","dataset: str = \"MovieLens1M\"\n","\n","# basic settings\n","\n","star4pos: int = 0\n","kcore4user: int = 5\n","kcore4item: int = 5\n","ratios: Tuple[int, int, int] = (8, 1, 1)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Converter\n","\n","converter: AtomicConverter = AtomicConverter(\n","    root=root,\n","    filename=filename,\n","    dataset=dataset\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[Converter] >>> Load `ml-1m.inter' ...\n","[Converter] >>> Load `ml-1m.user' ...\n","[Converter] >>> Load `ml-1m.item' ...\n","[Converter] >>> Filter dataframe according to Rating ...\n","[Converter] >>> Filter dataframe: User in [5, inf]; Item in [5, inf] ...\n","[Converter] >>> Current datasize: 1000209 ...\n","[Converter] >>> Current datasize: 999611\n","[Converter] >>> Current datasize: 999611\n","[Converter] >>> Map user ID to Token ...\n","[Converter] >>> Map item ID to Token ...\n","[Converter] >>> Sort by [User] [Timestamp] ...\n","[Converter] >>> Reserve fields: ['User', 'Item'] ...\n","[Converter] >>> Split by ratios: (8, 1, 1) ...\n","[Converter] >>> Save `train.txt' to ../RecSets/file_\\General\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `valid.txt' to ../RecSets/file_\\General\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `test.txt' to ../RecSets/file_\\General\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `user.txt' to ../RecSets/file_\\General\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `item.txt' to ../RecSets/file_\\General\\MovieLens1M_550811_Chron ...\n","+-------+-------+---------------+--------+--------+--------+----------------------+\n","| #User | #Item | #Interactions | #Train | #Valid | #Test  |       Density        |\n","+-------+-------+---------------+--------+--------+--------+----------------------+\n","|  6040 |  3416 |     999611    | 797275 | 99639  | 102697 | 0.048448041549699894 |\n","+-------+-------+---------------+--------+--------+--------+----------------------+\n"]}],"source":["# Make General dataset by ratios\n","\n","converter.make_general_dataset(\n","    star4pos=star4pos,\n","    kcore4user=kcore4user,\n","    kcore4item=kcore4item,\n","    ratios=ratios,\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[Converter] >>> Load `ml-1m.inter' ...\n","[Converter] >>> Load `ml-1m.user' ...\n","[Converter] >>> Load `ml-1m.item' ...\n","[Converter] >>> Filter dataframe according to Rating ...\n","[Converter] >>> Filter dataframe: User in [5, inf]; Item in [5, inf] ...\n","[Converter] >>> Current datasize: 1000209 ...\n","[Converter] >>> Current datasize: 999611\n","[Converter] >>> Current datasize: 999611\n","[Converter] >>> Map user ID to Token ...\n","[Converter] >>> Map item ID to Token ...\n","[Converter] >>> Sort by [User] [Timestamp] ...\n","[Converter] >>> Reserve fields: ['User', 'Item', 'Timestamp'] ...\n","[Converter] >>> Split by leaving last two ...\n","[Converter] >>> Save `train.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550_Chron ...\n","[Converter] >>> Save `valid.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550_Chron ...\n","[Converter] >>> Save `test.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550_Chron ...\n","[Converter] >>> Save `user.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550_Chron ...\n","[Converter] >>> Save `item.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550_Chron ...\n","+-------+-------+---------------+--------+--------+-------+----------------------+\n","| #User | #Item | #Interactions | #Train | #Valid | #Test |       Density        |\n","+-------+-------+---------------+--------+--------+-------+----------------------+\n","|  6040 |  3416 |     999611    | 987531 |  6040  |  6040 | 0.048448041549699894 |\n","+-------+-------+---------------+--------+--------+-------+----------------------+\n"]}],"source":["# Make Sequential dataset by leaving last two\n","\n","converter.make_sequential_dataset(\n","    star4pos=star4pos,\n","    kcore4user=kcore4user,\n","    kcore4item=kcore4item,\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[Converter] >>> Load `ml-1m.inter' ...\n","[Converter] >>> Load `ml-1m.user' ...\n","[Converter] >>> Load `ml-1m.item' ...\n","[Converter] >>> Filter dataframe according to Rating ...\n","[Converter] >>> Filter dataframe: User in [5, inf]; Item in [5, inf] ...\n","[Converter] >>> Current datasize: 1000209 ...\n","[Converter] >>> Current datasize: 999611\n","[Converter] >>> Current datasize: 999611\n","[Converter] >>> Map user ID to Token ...\n","[Converter] >>> Map item ID to Token ...\n","[Converter] >>> Sort by [User] [Timestamp] ...\n","[Converter] >>> Reserve fields: ['User', 'Item', 'Timestamp'] ...\n","[Converter] >>> Split by ratios: (8, 1, 1) ...\n","[Converter] >>> Save `train.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `valid.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `test.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `user.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550811_Chron ...\n","[Converter] >>> Save `item.txt' to ../RecSets/file_\\Sequential\\MovieLens1M_550811_Chron ...\n","+-------+-------+---------------+--------+--------+--------+----------------------+\n","| #User | #Item | #Interactions | #Train | #Valid | #Test  |       Density        |\n","+-------+-------+---------------+--------+--------+--------+----------------------+\n","|  6040 |  3416 |     999611    | 796232 | 96735  | 106644 | 0.048448041549699894 |\n","+-------+-------+---------------+--------+--------+--------+----------------------+\n"]}],"source":["# Make Sequential dataset by ratios\n","\n","converter.make_sequential_dataset_by_ratio(\n","    star4pos=star4pos,\n","    kcore4user=kcore4user,\n","    kcore4item=kcore4item,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('PyTorch12')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ddac72936d522153ec3ac6d97f1f11baa893034791f73796cb5411ad7575b00e"}}},"nbformat":4,"nbformat_minor":2}
